{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c1632-4102-4537-8ebf-02c56a39f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model:sklearn_utils.ScikitModel, X:pd.DataFrame, y, train_indices:np.ndarray, test_indices):\n",
    "    X_train, X_test = X.iloc[train_indices, :], X.iloc[test_indices, :]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    model.fit(X_train, y_train)\n",
    "    metrics_dict = calculate_clf_metrics_averaged(model, X_test, y_test)._asdict()\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2473e0c-4b0a-41e8-8cde-8da90e433801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val(model:sklearn_utils.ScikitModel, X:pd.DataFrame, y:np.ndarray, cv:int=5):\n",
    "    skf = StratifiedKFold(cv=cv)\n",
    "    output = Parallel()( delayed(train_model)(\n",
    "        model, X, y, \n",
    "        train_indices, \n",
    "        test_indices\n",
    "    ) for train_indecies, test_indecies in skf)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc9ad8-a2a8-4e01-a747-eb1f17a0a05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f55f5a6f-5f86-448e-a1aa-97b931ae58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(experiment_name:str, X_train:pd.DataFrame, y_train:np.ndarray,\n",
    "                   X_test:pd.DataFrame, y_test:np.ndarray, \n",
    "                   models:dict[str, sklearn_utils.ScikitModel], \n",
    "                   artifacts_folder:Path=None):\n",
    "\n",
    "    if artifacts_folder is None:\n",
    "        experiment_dirname = f'exp_{experiment_name}_artifacts'\n",
    "        artifacts_folder = files_utils.create_dir(experiment_dirname, replace_existing=True)\n",
    "    elif not Path.is_dir(artifacts_folder):\n",
    "        raise OSError(f'Directory \"{artifacts_folder}\" doesn\\'t exist, you may want to create it first.')\n",
    "\n",
    "    train_data_path = artifacts_folder/'X_train.csv'\n",
    "    test_data_path = artifacts_folder/'y_train.txt'\n",
    "    X_train.to_csv(train_data_path, index=False)\n",
    "    np.savetxt(test_data_path, y_train, delimiter=',')\n",
    "    \n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    progress_bar_models = tqdm(models.items())\n",
    "    for model_name, model in progress_bar_models:\n",
    "        progress_bar_models.set_description(f'Logging model [ {model_name} ]')\n",
    "        \n",
    "        with mlflow.start_run(run_name=f'{model_name}_run'):\n",
    "            # logging training data\n",
    "            # train_data = mlflow.data.from_pandas(X_train, train_data_path)\n",
    "            # test_data = mlflow.data.from_numpy(y_train, test_data_path)\n",
    "            # dataset = {\"X_train\": train_data, \n",
    "            #            \"y_train\": test_data}\n",
    "            # for name, data in dataset.items():\n",
    "            #     mlflow.log_input(data, context=get_data_context(name))\n",
    "\n",
    "            # Model fitting and calculating metrics\n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_test)\n",
    "            pred_probas = model.predict_proba(X_test)\n",
    "            metrics_dict = calculate_clf_metrics_averaged(model, X_test, y_test)._asdict()\n",
    "\n",
    "            # logging the metrics\n",
    "            for metric_name, metric_value in metrics_dict.items():\n",
    "                mlflow.log_metric(metric_name, metric_value)\n",
    "    \n",
    "            # logging the model\n",
    "            mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "            # logging metrics visualizations\n",
    "            extension = 'png'\n",
    "            \n",
    "            plt.ioff()\n",
    "            \n",
    "            cm_filename = f'confusion_matrix_{model_name}'\n",
    "            cm_path = artifacts_folder/f\"{cm_filename}.{extension}\"\n",
    "            cm = visualize_confusion_matrix(y_test, pred, labels=['Poor', 'Standard', 'Good'])\n",
    "            save_visualization(cm, cm_path)\n",
    "            mlflow.log_artifact(cm_path, cm_filename)\n",
    "            \n",
    "            \n",
    "            roc_auc_filename = f'roc_auc_{model_name}'\n",
    "            roc_auc_path = artifacts_folder/f\"{roc_auc_filename}.{extension}\"\n",
    "            roc_auc_display = visualize_roc(y_test, pred_probas, ['Poor', 'Standard', 'Good'])\n",
    "            save_visualization(roc_auc_display, roc_auc_path)\n",
    "            mlflow.log_artifact(roc_auc_path, roc_auc_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
